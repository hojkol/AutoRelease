import requests

# URL
# https://daocloud.feishu.cn/wiki/HmLyw7ru0ik1w8k4AkNcD6UhnKf?table=tblxfFwc9An4pWGJ&view=vew0rjziyc
# https://daocloud.feishu.cn/wiki/UE8Dw2b4Xi665ukTHEtcnVZ5nlc?base_hp_from=larktab&table=tblo4cOyNujdQc2g&view=vew0rjziyc


import json
import csv
from datetime import datetime, timezone
import pandas as pd
from collections import OrderedDict




APP_ID = "cli_a8a4209df579901c"
APP_SECRET = "jDngWS3tVibuaxxod5jB0cpUkpd3paOS"
NODE_TOKEN = "UE8Dw2b4Xi665ukTHEtcnVZ5nlc"  # è¡¨æ ¼é“¾æ¥ä¸­ /sheets/ åé¢çš„é‚£ä¸²å­—ç¬¦
TABLE_ID = "tblo4cOyNujdQc2g"        # å·¥ä½œè¡¨IDï¼Œé€šå¸¸ä¸º "Sheet1" æˆ–ç±»ä¼¼
VIEW_ID = "vew0rjziyc"

ITEM_HEADER = [
    'åŠŸèƒ½æ¨¡å—',
    'å‘å¸ƒç‰ˆæœ¬',
    'å‘ç‰ˆæ—¶é—´',
    'æ›´æ–°ç±»å‹',
    'ä¸€çº§åŠŸèƒ½',
    'äºŒçº§åŠŸèƒ½',
    'åŸºçº¿å‚æ•°'
]



# 1. è·å– tenant_access_token
def get_tenant_access_token(app_id, app_secret):
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal/"
    payload = {"app_id": app_id, "app_secret": app_secret}
    resp = requests.post(url, json=payload)
    return resp.json()["tenant_access_token"]

# 2. é€šè¿‡ node_token è·å–è¯¥çŸ¥è¯†ç©ºé—´èŠ‚ç‚¹ä¿¡æ¯ï¼Œæœ‰ apace_id, æŒ‚è½½çš„äº‘èµ„æºçš„ obj_token å’Œ obj_type
def get_node_info(node_token, tenant_access_token):
    url = "https://open.feishu.cn/open-apis/wiki/v2/spaces/get_node"
    headers = {"Authorization": f"Bearer {tenant_access_token}"}
    params = {"token": node_token, "obj_type": "wiki"}
    resp = requests.get(url, params=params, headers=headers)
    return resp.json()


# 3. è¯»å–è¡¨æ ¼å†…å®¹
def get_sheet_content(app_token, table_id, tenant_access_token, page_size=100, page_token=None):
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records/search"
    headers = {
        "Authorization": f"Bearer {tenant_access_token}",
        "Content-Type": "application/json"
    }
    payload = {
        "view_id": VIEW_ID,
        # å¯æ ¹æ®éœ€è¦æ·»åŠ ç­›é€‰æ¡ä»¶ filterã€æ’åºç­‰
    }
    resp = requests.post(url, headers=headers, data=json.dumps(payload))
    return resp.json()


def get_cotent_according_to_record_id(app_token, tenant_access_token, record_id):
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{app_token}/tables/{TABLE_ID}/records/search"
    headers = {
        "Authorization": f"Bearer {tenant_access_token}",
        "Content-Type": "application/json"
    }
    record_id = [record_id] if isinstance(record_id, str) else record_id
    payload = {
        "record_ids": record_id
    }
    resp = requests.post(url, headers=headers, data=json.dumps(payload))
    return resp.json()


def get_items(data):
    items = data['data']['items']
    
    filter_items = []
    # CSVè¡¨å¤´

    filter_items.append(ITEM_HEADER)
    for item in items:
        fields = item['fields']

        # å¤„ç†å¤šæ–‡æœ¬å­—æ®µï¼Œæå–"text"å¹¶ç”¨é€—å·è¿æ¥
        first_level = ','.join([x['text'] for x in fields.get('ä¸€çº§åŠŸèƒ½', [])]) if fields.get('ä¸€çº§åŠŸèƒ½') else ''
        second_level = ','.join([x['text'] for x in fields.get('äºŒçº§åŠŸèƒ½', [])]) if fields.get('äºŒçº§åŠŸèƒ½') else ''
        baseline = ','.join([x['text'] for x in fields.get('åŸºçº¿å‚æ•°', [])]) if fields.get('åŸºçº¿å‚æ•°') else ''
        # product_version = ','.join([x['text'] for x in fields.get('äº§å“æ¨¡å—ç‰ˆæœ¬', [])]) if fields.get('å‘å¸ƒç‰ˆæœ¬') else ''
        version = fields.get('ç‰ˆæœ¬', {})['value'][0]['text'] if fields.get('ç‰ˆæœ¬') else ''
        release_time = fields.get('å‘ç‰ˆæ—¶é—´', {})
        if release_time and 'value' in release_time and release_time['value']:
            # æ—¶é—´æˆ³å•ä½ä¸ºæ¯«ç§’ï¼Œè½¬æ¢ä¸ºç§’åè½¬æ—¥æœŸ
            timestamp = int(release_time['value'][0]) / 1000
            normal_date = datetime.fromtimestamp(timestamp, timezone.utc).strftime('%Y-%m-%d')
        else:
            normal_date = None
        row = [
            fields.get('åŠŸèƒ½æ¨¡å—', ''),
            version,
            normal_date,
            fields.get('æ›´æ–°ç±»å‹', ''),
            first_level,
            second_level,
            baseline
        ]
        # åªä¿ç•™ äº§å“æ¨¡å—ç‰ˆæœ¬ ä¸ä¸ºç©ºçš„è¡Œ
        if version:
            filter_items.append(row)

    with open('output1.csv', mode='w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        for i in filter_items:
            writer.writerow(i)


    return filter_items


def get_release_Dict(data):
    # è½¬æˆDataFrame
    df = pd.DataFrame(data[1:], columns=data[0])

    def version_key(v):
        parts = v.lstrip('v').split('.')
        return tuple(int(x) for x in parts)

    df['ç‰ˆæœ¬æ’åº'] = df['å‘å¸ƒç‰ˆæœ¬'].apply(version_key)

    # è‡ªå®šä¹‰æ’åºæ˜ å°„
    module_order = {'ç®—åŠ›äº‘': 0, 'å¤§æ¨¡å‹æœåŠ¡å¹³å°': 1, 'è´¹ç”¨ä¸­å¿ƒ': 2, 'ç”¨æˆ·ä¸­å¿ƒ': 3}
    update_type_order = {'æ–°åŠŸèƒ½': 0, 'å¢å¼ºä¼˜åŒ–': 1, 'æ•…éšœä¿®å¤': 2, 'æ— æ›´æ–°ç±»å‹': 3}

    # æ›¿æ¢ç©ºæ›´æ–°ç±»å‹ä¸º'æ— æ›´æ–°ç±»å‹'
    df['æ›´æ–°ç±»å‹'] = df['æ›´æ–°ç±»å‹'].replace({'': 'æ— æ›´æ–°ç±»å‹'})

    # æ·»åŠ æ’åºè¾…åŠ©åˆ—
    df['åŠŸèƒ½æ¨¡å—æ’åº'] = df['åŠŸèƒ½æ¨¡å—'].map(module_order).fillna(99)
    df['æ›´æ–°ç±»å‹æ’åº'] = df['æ›´æ–°ç±»å‹'].map(update_type_order).fillna(99)

    # æŒ‰è¦æ±‚æ’åºï¼š
    # 1. å‘ç‰ˆæ—¶é—´é™åº
    # 2. åŠŸèƒ½æ¨¡å—è‡ªå®šä¹‰é¡ºåºå‡åº
    # 3. ç‰ˆæœ¬å·å‡åº
    # 4. æ›´æ–°ç±»å‹è‡ªå®šä¹‰é¡ºåºå‡åº
    # 5. ä¸€çº§åŠŸèƒ½å‡åº
    df_sorted = df.sort_values(by=['å‘ç‰ˆæ—¶é—´', 'åŠŸèƒ½æ¨¡å—æ’åº', 'ç‰ˆæœ¬æ’åº', 'æ›´æ–°ç±»å‹æ’åº', 'ä¸€çº§åŠŸèƒ½'],
                            ascending=[False, True, True, True, True])

    # æ„å»ºæœ‰åºå­—å…¸ç»“æ„
    result = OrderedDict()

    for _, row in df_sorted.iterrows():
        pub_date = row['å‘ç‰ˆæ—¶é—´']
        module = row['åŠŸèƒ½æ¨¡å—']
        version = row['å‘å¸ƒç‰ˆæœ¬']
        update_type = row['æ›´æ–°ç±»å‹']
        primary_func = row['ä¸€çº§åŠŸèƒ½']
        entry = {
            'äºŒçº§åŠŸèƒ½': row['äºŒçº§åŠŸèƒ½'],
            'åŸºçº¿å‚æ•°': row['åŸºçº¿å‚æ•°']
        }
        
        if pub_date not in result:
            result[pub_date] = OrderedDict()
        if module not in result[pub_date]:
            result[pub_date][module] = OrderedDict()
        if version not in result[pub_date][module]:
            result[pub_date][module][version] = OrderedDict()
        if update_type not in result[pub_date][module][version]:
            result[pub_date][module][version][update_type] = []
        
        result[pub_date][module][version][update_type].append((primary_func, entry))

    # ç»„å†…ä¸€çº§åŠŸèƒ½å†æ¬¡æ’åº
    for pub_date in result:
        for module in result[pub_date]:
            for version in result[pub_date][module]:
                for update_type in result[pub_date][module][version]:
                    result[pub_date][module][version][update_type].sort(key=lambda x: x[0])
    # # æ‰“å°ç»“æœç¤ºä¾‹
    # import pprint
    # pp = pprint.PrettyPrinter(indent=2, width=120)
    # pp.pprint(result)
    return result


def get_release_info(result):
    # result[å‘å¸ƒæ—¥æœŸ][åŠŸèƒ½æ¨¡å—][ç‰ˆæœ¬å·][æ›´æ–°ç±»å‹] = [(ä¸€çº§åŠŸèƒ½, {äºŒçº§åŠŸèƒ½, åŸºçº¿å‚æ•°}), ...]

    # æ—¥æœŸæ ¼å¼è½¬æ¢å‡½æ•°
    def format_date(date_str):
        return datetime.strptime(date_str, '%Y%m%d').strftime('%Y-%m-%d')

    # æ›´æ–°ç±»å‹å¯¹åº”çš„ Emoji å’Œæ ‡é¢˜
    emoji_map = {
        'æ–°åŠŸèƒ½': 'ğŸš€ æ–°åŠŸèƒ½',
        'å¢å¼ºä¼˜åŒ–': 'âš¡ å¢å¼ºä¼˜åŒ–',
        'æ•…éšœä¿®å¤': 'ğŸ› æ•…éšœä¿®å¤',
        'æ— æ›´æ–°ç±»å‹': ''  # ç©ºæ›´æ–°ç±»å‹ä¸æ˜¾ç¤ºæ ‡é¢˜å’Œ Emoji
    }

    # ç”Ÿæˆ Markdown å†…å®¹
    lines = []
    lines.append('---')
    lines.append('hide:')
    lines.append('  - toc')
    lines.append('---\n')
    lines.append('# Release Notes\n')
    lines.append('æœ¬é¡µåˆ—å‡º d.run å„é¡¹åŠŸèƒ½çš„ä¸€äº›é‡è¦å˜æ›´ã€‚\n')

    # éå†æ—¥æœŸï¼ˆå·²æ’åºï¼‰
    for pub_date, modules in result.items():
        # lines.append(f'## {format_date(pub_date)}\n')
        lines.append(f'## {pub_date}\n')
        # éå†åŠŸèƒ½æ¨¡å—
        for module, versions in modules.items():
            # éå†ç‰ˆæœ¬å·
            for version, update_types in versions.items():
                lines.append(f'### {module} {version}\n')

                # æŒ‰å›ºå®šé¡ºåºè¾“å‡ºæ›´æ–°ç±»å‹
                for update_type in ['æ–°åŠŸèƒ½', 'å¢å¼ºä¼˜åŒ–', 'æ•…éšœä¿®å¤', 'æ— æ›´æ–°ç±»å‹']:
                    if update_type in update_types:
                        entries = update_types[update_type]
                        # éç©ºæ›´æ–°ç±»å‹è¾“å‡ºæ ‡é¢˜
                        if update_type != 'æ— æ›´æ–°ç±»å‹':
                            lines.append(f'#### {emoji_map[update_type]}\n')
                        # è¾“å‡ºæ¯æ¡è®°å½•ï¼Œæ ¼å¼ï¼š- [ä¸€çº§åŠŸèƒ½] åŸºçº¿å‚æ•°ï¼ˆè‹¥åŸºçº¿å‚æ•°ä¸ºç©ºåˆ™åªæ˜¾ç¤ºä¸€çº§åŠŸèƒ½ï¼‰
                        for primary_func, entry in entries:
                            baseline = entry['åŸºçº¿å‚æ•°']
                            if baseline:
                                lines.append(f'- [{primary_func}] {baseline}')
                            else:
                                lines.append(f'- [{primary_func}]')
                        lines.append('')  # æ¯ä¸ªæ›´æ–°ç±»å‹åç©ºè¡Œ

    md_content = '\n'.join(lines)

    # ä¿å­˜ä¸ºæ–‡ä»¶
    with open('release_notes.md', 'w', encoding='utf-8') as f:
        f.write(md_content)


if __name__ == "__main__":

    tenant_access_token = get_tenant_access_token(APP_ID, APP_SECRET)
    node_info = get_node_info(NODE_TOKEN, tenant_access_token)
    app_token = node_info["data"]["node"]["obj_token"]
    ori_data = get_sheet_content(app_token, TABLE_ID, tenant_access_token)
    # print(ori_data)
    items = get_items(ori_data)
    release_note = get_release_Dict(items)
    get_release_info(release_note)

